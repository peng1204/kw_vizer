import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
import json

# 1. ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = chromadb.Client(Settings())

# 2. Collection ë§Œë“¤ê¸°
collection = client.get_or_create_collection(name="lecture_data")

# 3. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

# 4. JSON íŒŒì¼ ì½ê¸°
with open('/Users/hyunjin/Desktop/kw_vizer/ìˆ˜ê°•ì‹ ì²­ìë£Œì§‘.json', 'r', encoding='utf-8') as f:
    lectures = json.load(f)

# 5. documents, ids, metadatas ì¤€ë¹„
documents = []
ids = []
metadatas = []

# ì¤‘ë³µ ì²´í¬ìš© dict
id_count = {}

for lec in lectures:
    # document ë§Œë“¤ê¸°
    doc = f"{lec.get('lecture_name', '')} {lec.get('ë‹´ë‹¹êµìˆ˜', '')} {lec.get('ê°•ì˜ì‹œê°„', '')} {lec.get('ê°•ì˜ìœ í˜•', '')}"
    documents.append(doc)

    # id ì²˜ë¦¬
    base_id = lec.get('lecture_id', '')
    if base_id in id_count:
        id_count[base_id] += 1
        new_id = f"{base_id}_{id_count[base_id]}"  # ì¤‘ë³µë  ê²½ìš° _1, _2 ë¶™ì´ê¸°
    else:
        id_count[base_id] = 0
        new_id = base_id

    ids.append(new_id)

    # metadata
    metadatas.append({
        "lecture_id": base_id,
        "lecture_name": lec.get('lecture_name', ''),
        "ë‹´ë‹¹êµìˆ˜": lec.get('ë‹´ë‹¹êµìˆ˜', ''),
        "í•™ì ": lec.get('í•™ì ', ''),
        "ì´ìˆ˜": lec.get('ì´ìˆ˜', '')
    })

# 6. ë¬¸ì„œë“¤ì„ ì„ë² ë”©
embeddings = model.encode(documents).tolist()

# 7. ChromaDBì— ì‚½ì…
collection.add(
    documents=documents,
    embeddings=embeddings,
    metadatas=metadatas,
    ids=ids
)

print("âœ… ë°ì´í„° ì‚½ì… ì™„ë£Œ!\n")

# 8. Embedding ê²°ê³¼ ì¶œë ¥
print("ğŸ“ˆ ìƒì„±ëœ Embedding ë²¡í„°ë“¤:")
for emb in embeddings:
    print(emb)

    # 9. ì§ˆë¬¸ ì…ë ¥ ë°›ì•„ì„œ ê²€ìƒ‰í•˜ëŠ” ê¸°ëŠ¥
while True:
    user_question = input("\nğŸ” ê²€ìƒ‰í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥): ")
    
    if user_question.lower() == "exit":
        print("ğŸ‘‹ ê²€ìƒ‰ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        break

    if not user_question.strip():
        print("âš ï¸ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        continue

    # ì§ˆë¬¸ì„ ì„ë² ë”©
    query_embedding = model.encode([user_question]).tolist()

    # ChromaDBì—ì„œ ë¹„ìŠ·í•œ ê²°ê³¼ ê²€ìƒ‰
    results = collection.query(
        query_embeddings=query_embedding,
        n_results=5,  # ê¸°ë³¸ 5ê°œ ë³´ì—¬ì¤Œ
        include=['metadatas', 'documents', 'distances']  # ìœ ì‚¬ë„ ì ìˆ˜(distance) í¬í•¨í•´ì„œ ë°›ê¸°
    )

    documents = results['documents'][0]
    metadatas = results['metadatas'][0]
    distances = results['distances'][0]

    if not documents:
        print("ğŸ˜¥ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”!")
        continue

    print("\nğŸ“š ê²€ìƒ‰ ê²°ê³¼:")
    for doc, meta, distance in zip(documents, metadatas, distances):
        similarity_score = (1 - distance) * 100  # ìœ ì‚¬ë„ë¥¼ %ë¡œ ë³€í™˜
        print(f"- [{similarity_score:.2f}% ì¼ì¹˜] ê°•ì˜ëª…: {meta['lecture_name']} | êµìˆ˜ëª…: {meta['ë‹´ë‹¹êµìˆ˜']} | í•™ì : {meta['í•™ì ']} | ì´ìˆ˜êµ¬ë¶„: {meta['ì´ìˆ˜']}")