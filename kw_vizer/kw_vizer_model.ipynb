{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5f44c8-0494-45b0-97e0-d8627a641bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install langchain langchain-openai langchain-community langchain-text-splitters sentence-transformers pypdfium2 chromadb langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d57e7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë“  Chroma DB ê²½ë¡œ ì™„ì „ ì‚­ì œ ì™„ë£Œ â€” ì»¤ë„ ì¬ì‹œì‘ í›„ ê³„ì†í•˜ì„¸ìš”\n"
     ]
    }
   ],
   "source": [
    "## í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì‚¬ìš©\n",
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. í”„ë¡œì íŠ¸ í´ë” ë‚´ Chroma ë””ë ‰í† ë¦¬ ì‚­ì œ\n",
    "shutil.rmtree(\"./chroma_db\", ignore_errors=True)\n",
    "\n",
    "# 2. ì‚¬ìš©ì í™ˆ í´ë” ì•„ë˜ Chroma ìºì‹œ ì‚­ì œ\n",
    "shutil.rmtree(Path.home() / \".chromadb\", ignore_errors=True)\n",
    "\n",
    "# 3. Windows LocalAppData ê²½ë¡œ ì‚­ì œ (ìˆ¨ê²¨ì§„ ë¬¸ì œ í”í•¨)\n",
    "shutil.rmtree(Path.home() / \"AppData\" / \"Local\" / \"chromadb\", ignore_errors=True)\n",
    "\n",
    "print(\"ëª¨ë“  Chroma DB ê²½ë¡œ ì™„ì „ ì‚­ì œ ì™„ë£Œ â€” ì»¤ë„ ì¬ì‹œì‘ í›„ ê³„ì†í•˜ì„¸ìš”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f01177-e2c3-4165-bfa4-6423cc34c86d",
   "metadata": {},
   "source": [
    "#### ì„ë² ë”© ëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278565e2-6c09-4a24-933e-6e7655fc2ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[kim] ì„ë² ë”© ì™„ë£Œ (24ê±´)\n",
      "[hong] ì„ë² ë”© ì™„ë£Œ (24ê±´)\n",
      "[lecture_search] ì„ë² ë”© ì™„ë£Œ (617ê±´)\n",
      "[career_counsel] ì„ë² ë”© ì™„ë£Œ (639ê±´)\n",
      "[academic_status] ì„ë² ë”© ì™„ë£Œ (607ê±´)\n",
      " 'lecture_search' PDF ì„ë² ë”© 423ê°œ ì¶”ê°€ ì™„ë£Œ\n",
      " 'career_counsel' PDF ì„ë² ë”© 423ê°œ ì¶”ê°€ ì™„ë£Œ\n",
      " 'academic_status' PDF ì„ë² ë”© 423ê°œ ì¶”ê°€ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ì „ì²´ Chroma DB ì‚­ì œ (ê¸°ë³¸ ë””ë ‰í† ë¦¬ì™€ ì‹œìŠ¤í…œ ìºì‹œ í¬í•¨)\n",
    "shutil.rmtree(\"./chroma_db\", ignore_errors=True)\n",
    "shutil.rmtree(Path.home() / \".chromadb\", ignore_errors=True)\n",
    "\n",
    "import os\n",
    "import json\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import chromadb\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"dd\"\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "def load_json_documents(json_files):\n",
    "    docs = []\n",
    "    for file in json_files:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        #ì‹œë‚˜ë¦¬ì˜¤\n",
    "        for item in data:\n",
    "            if \"Text\" in item and \"Completion\" in item:\n",
    "                docs.append(Document(\n",
    "                    page_content=f\"ì§ˆë¬¸: {item['Text']}\\në‹µë³€: {item['Completion']}\",\n",
    "                    metadata={\n",
    "                        \"ì¹´í…Œê³ ë¦¬\": item.get(\"ì¹´í…Œê³ ë¦¬\", \"\")\n",
    "                    }\n",
    "                ))\n",
    "\n",
    "            # ìˆ˜ê°•ì´ë ¥\n",
    "            if \"lecture_name\" in item and \"student_id\" in item:\n",
    "                content = (\n",
    "                    f\"í•™ë²ˆ: {item['student_id']}\\n\"\n",
    "                    f\"ê°•ì˜ëª…: {item['lecture_name']}\\n\"\n",
    "                    f\"í•™ì •ë²ˆí˜¸: {item['lecture_id']}\\n\"\n",
    "                    f\"ê°œì„¤ í•™ê³¼: {item['department_offered']}\\n\"\n",
    "                    f\"ì´ìˆ˜ êµ¬ë¶„: {item['lecture_course_type']}\\n\"\n",
    "                    f\"í•™ì : {item['lecture_credit']}í•™ì \\n\"\n",
    "                    f\"ì„±ì : {item['lecutre_grade']}\"\n",
    "                )\n",
    "                if \"retake_or_delete_status\" in item:\n",
    "                    content += f\"\\nì¬ìˆ˜ê°•/ì‚­ì œ ì—¬ë¶€: {item['retake_or_delete_status']}\"\n",
    "                if \"retake_status\" in item:\n",
    "                    content += f\"\\nì¬ìˆ˜ê°• ì—¬ë¶€: {item['retake_status']}\"\n",
    "\n",
    "                docs.append(Document(\n",
    "                    page_content=content,\n",
    "                    metadata={\n",
    "                        \"lecture_name\": item[\"lecture_name\"],\n",
    "                        \"course_type\": item[\"lecture_course_type\"]\n",
    "                    }\n",
    "                ))\n",
    "\n",
    "            # ê°•ì˜ íƒìƒ‰\n",
    "            if \"lecture_id\" in item and \"lecture_name\" in item and \"student_id\" not in item:\n",
    "                content = (\n",
    "                    f\"í•™ì •ë²ˆí˜¸: {item.get('lecture_id', '')}\\n\"\n",
    "                    f\"ê°•ì˜ëª…: {item.get('lecture_name', '')}\\n\"\n",
    "                    f\"ê°•ì˜í‰ì : {item.get('lecture_ratings', '')}\\n\"\n",
    "                    f\"ê³¼ì œ: {item.get('lecture_homework', '')}\\n\"\n",
    "                    f\"íŒ€í”Œ: {item.get('lecture_team', '')}\\n\"\n",
    "                    f\"ì„±ì í‰ê°€ì •ë„: {item.get('lecutre_grade', '')}\\n\"\n",
    "                    f\"ì¶œê²° ë°©ì‹: {item.get('lecutre_attendance', '')}\\n\"\n",
    "                    f\"ì‹œí—˜ íšŸìˆ˜: {item.get('lecutre_test', '')}\\n\"\n",
    "                    f\"ì‹œí—˜ ë°©ì‹: {item.get('lecture_testinform', '')}\\n\"\n",
    "                    f\"ì „ê³µ í•™ì : {item.get('credits_major', 'ì—†ìŒ')}\\n\"\n",
    "                    f\"êµì–‘ í•™ì : {item.get('credits_general', 'ì—†ìŒ')}\\n\"\n",
    "                    f\"ì´ í•™ì : {item.get('credits_total', 'ì—†ìŒ')}\\n\"\n",
    "                    f\"êµìˆ˜ëª…: {item.get('lecture_professorname', '')}\\n\"\n",
    "                    f\"ìˆ˜ì—… ì‹œê°„: {item.get('lecture_time', '')}\\n\"\n",
    "                    f\"ê°•ì˜ ìœ í˜•: {item.get('lecture_course_type', '')}\\n\"\n",
    "                    f\"í•™ì : {item.get('lecture_hours', '')}ì‹œê°„\\n\"\n",
    "                    f\"í•™ê¸°: {item.get('lecture_semester', '')}í•™ê¸°\\n\"\n",
    "                    f\"ê°•ì˜ ì„¤ëª…: {item.get('lecture_inform', '')}\"\n",
    "                    f\"ì˜ì—­: {item.get('lecture_domain', '')}\\n\"\n",
    "                )\n",
    "                docs.append(Document(\n",
    "                    page_content=content,\n",
    "                    metadata={\n",
    "                        \"lecture_id\": item.get(\"lecture_id\", \"\"),\n",
    "                        \"lecture_name\": item.get(\"lecture_name\", \"\"),\n",
    "                        \"lecture_ratings\": item.get(\"lecture_ratings\", \"\"),\n",
    "                        \"lecture_team\": item.get(\"lecture_team\", \"\"),\n",
    "                        \"lecutre_grade\": item.get(\"lecutre_grade\", \"\"),\n",
    "                        \"professor\": item.get(\"lecture_professorname\", \"\")\n",
    "                    }\n",
    "                ))\n",
    "    return docs\n",
    "\n",
    "user_datasets = {\n",
    "    \"kim\": [\"data/kw_chatbot_data - ê¹€ë¸Œí‹°_ìˆ˜ê°•ì´ë ¥.json\"],\n",
    "    \"hong\": [\"data/kw_chatbot_data - í™ë°ì‚¬_ìˆ˜ê°•ì´ë ¥.json\"]\n",
    "}\n",
    "\n",
    "task_datasets = {\n",
    "    \"lecture_search\": [\n",
    "        \"data/kw_chatbot_data - Student.json\",\n",
    "        \"data/kw_chatbot_data - ê°•ì˜ í‰ì .json\",\n",
    "        \"data/kw_chatbot_data - ê°•ì˜ê³„íšì„œ.json\",\n",
    "        \"data/kw_chatbot_data - ê¹€ë¸Œí‹°_ì„±ì .json\",\n",
    "        \"data/kw_chatbot_data - ê¹€ë¸Œí‹°_ìˆ˜ê°•ì´ë ¥.json\",\n",
    "        \"data/kw_chatbot_data - ìˆ˜ê°•ì‹ ì²­ìë£Œì§‘.json\",\n",
    "        \"data/kw_chatbot_data - ì»¤ë¦¬í˜ëŸ¼(DS).json\",\n",
    "        \"data/kw_chatbot_data - ì»¤ë¦¬í˜ëŸ¼(VT).json\",\n",
    "        \"data/kw_chatbot_data - í™ë°ì‚¬_ì„±ì .json\",\n",
    "        \"data/kw_chatbot_data - í™ë°ì‚¬_ìˆ˜ê°•ì´ë ¥.json\",\n",
    "        \"data/lecture_domain.json\"\n",
    "    ],\n",
    "    \"career_counsel\": [\n",
    "        \"data/ì§„ë¡œìƒë‹´.json\",\n",
    "        \"data/kw_chatbot_data - ê°•ì˜ê³„íšì„œ.json\",\n",
    "        \"data/kw_chatbot_data - ê¹€ë¸Œí‹°_ì„±ì .json\",\n",
    "        \"data/kw_chatbot_data - ê¹€ë¸Œí‹°_ìˆ˜ê°•ì´ë ¥.json\",\n",
    "        \"data/kw_chatbot_data - ìˆ˜ê°•ì‹ ì²­ìë£Œì§‘.json\",\n",
    "        \"data/kw_chatbot_data - ì»¤ë¦¬í˜ëŸ¼(DS).json\",\n",
    "        \"data/kw_chatbot_data - ì»¤ë¦¬í˜ëŸ¼(VT).json\",\n",
    "        \"data/kw_chatbot_data - í™ë°ì‚¬_ì„±ì .json\",\n",
    "        \"data/kw_chatbot_data - í™ë°ì‚¬_ìˆ˜ê°•ì´ë ¥.json\"],\n",
    "    \n",
    "    \"academic_status\": [\n",
    "        \"data/í•™ìŠµí˜„í™©.json\",\n",
    "        \"data/kw_chatbot_data - Student.json\",\n",
    "        \"data/kw_chatbot_data - ê¹€ë¸Œí‹°_ì„±ì .json\",\n",
    "        \"data/kw_chatbot_data - ê¹€ë¸Œí‹°_ìˆ˜ê°•ì´ë ¥.json\",\n",
    "        \"data/kw_chatbot_data - ìˆ˜ê°•ì‹ ì²­ìë£Œì§‘.json\",\n",
    "        \"data/kw_chatbot_data - í™ë°ì‚¬_ì„±ì .json\",\n",
    "        \"data/kw_chatbot_data - í™ë°ì‚¬_ìˆ˜ê°•ì´ë ¥.json\",\n",
    "        \"data/lecture_domain.json\"\n",
    "        ]\n",
    "}\n",
    "\n",
    "# ì‚¬ìš©ìë³„ ì»¬ë ‰ì…˜\n",
    "for user_id, files in user_datasets.items():\n",
    "    collection_name = f\"lecture_search_{user_id}\"\n",
    "    try:\n",
    "        client.delete_collection(name=collection_name)\n",
    "    except:\n",
    "        pass\n",
    "    docs = load_json_documents(files)\n",
    "    split_docs = text_splitter.split_documents(docs)\n",
    "    texts = [doc.page_content for doc in split_docs]\n",
    "    embeddings = embeddings_model.embed_documents(texts)\n",
    "    collection = client.create_collection(name=collection_name)\n",
    "    collection.add(\n",
    "        documents=texts,\n",
    "        embeddings=embeddings,\n",
    "        ids=[f\"{collection_name}_{i}\" for i in range(len(texts))]\n",
    "    )\n",
    "    print(f\"[{user_id}] ì„ë² ë”© ì™„ë£Œ ({len(embeddings)}ê±´)\")\n",
    "\n",
    "# ê¸°ëŠ¥ë³„ ì»¬ë ‰ì…˜\n",
    "for task, files in task_datasets.items():\n",
    "    try:\n",
    "        client.delete_collection(name=task)\n",
    "    except:\n",
    "        pass\n",
    "    docs = load_json_documents(files)\n",
    "    split_docs = text_splitter.split_documents(docs)\n",
    "    texts = [doc.page_content for doc in split_docs]\n",
    "    embeddings = embeddings_model.embed_documents(texts)\n",
    "    collection = client.create_collection(name=task)\n",
    "    collection.add(\n",
    "        documents=texts,\n",
    "        embeddings=embeddings,\n",
    "        ids=[f\"{task}_{i}\" for i in range(len(texts))]\n",
    "    )\n",
    "    print(f\"[{task}] ì„ë² ë”© ì™„ë£Œ ({len(embeddings)}ê±´)\")\n",
    "    \n",
    "# PDF ë¬¸ì„œ ì„ë² ë”© ì¶”ê°€\n",
    "target_collections = [\"lecture_search\", \"career_counsel\", \"academic_status\"]\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = PyPDFLoader(\"data/ìˆ˜ê°•ì‹ ì²­_ìë£Œì§‘_ì „ì²´(2025-1)v4.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "texts = [doc.page_content for doc in docs]\n",
    "embeddings = embeddings_model.embed_documents(texts)\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "#ì»¬ë ‰ì…˜ì— ì¶”ê°€\n",
    "for name in target_collections:\n",
    "    collection = client.get_or_create_collection(name=name)\n",
    "    collection.add(\n",
    "        documents=texts,\n",
    "        embeddings=embeddings,\n",
    "        ids=[f\"{name}_pdf_{i}\" for i in range(len(texts))]\n",
    "    )\n",
    "    print(f\" '{name}' PDF ì„ë² ë”© {len(texts)}ê°œ ì¶”ê°€ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab960d5d-5a2c-426a-91ae-34d88ad8b22e",
   "metadata": {},
   "source": [
    "#### ê¸°ëŠ¥ êµ¬í˜„ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f301fe0e-f465-41dd-afba-57c004dc7963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import random\n",
    "import itertools\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# LangChain ì»¬ë ‰ì…˜ ì´ë¦„ ê²°ì • í•¨ìˆ˜\n",
    "def get_collection_name(user_input: str, user_id: str) -> str:\n",
    "    q = user_input.lower()\n",
    "    if \"ì§„ë¡œ\" in q or \"ìƒë‹´\" in q:\n",
    "        return \"career_counsel\"\n",
    "    elif \"ì´ìˆ˜\" in q or \"í•™ì \" in q or \"í˜„í™©\" in q or \"í‰ê· \" in q:\n",
    "        return \"academic_status\"\n",
    "    return f\"lecture_search_{user_id}\"\n",
    "\n",
    "# ì…ë ¥ ë¶„ë¥˜ í•¨ìˆ˜\n",
    "def classify_function(user_input: str) -> str:\n",
    "    if \"ê°•ì˜\" in user_input or \"íƒìƒ‰\" in user_input:\n",
    "        return \"lecture_search\"\n",
    "    elif \"ì§„ë¡œ\" in user_input or \"ìƒë‹´\" in user_input:\n",
    "        return \"career_counsel\"\n",
    "    elif \"í•™ì—…\" in user_input or \"í˜„í™©\" in user_input:\n",
    "        return \"academic_status\"\n",
    "    else:\n",
    "        return \"lecture_search\"\n",
    "\n",
    "# ìºì‹œ: íŒ€í”Œ ì¡°ê±´ì— ë”°ë¼ ê²°ê³¼ ì¬ì‚¬ìš©\n",
    "TEAM_CACHE = {}\n",
    "\n",
    "# íŒ€í”Œ ì¡°ê±´ ë¬¸ìì—´ì„ í‘œì¤€í™”\n",
    "def normalize_team_condition(user_input):\n",
    "    lowered = user_input.lower()\n",
    "    lowered = re.sub(r\"[^\\w\\s]\", \"\", lowered)\n",
    "    words = lowered.split()\n",
    "    joined = \"\".join(words)\n",
    "\n",
    "    for word in [\"ì¡°ë³„ê³¼ì œ\", \"íŒ€í”Œ\"]:\n",
    "        if word in joined:\n",
    "            if any(w in joined for w in [\"ì—†ëŠ”\", \"ì—†ìŒ\"]):\n",
    "                return \"ì—†ìŒ\"\n",
    "            if any(w in joined for w in [\"ë³´í†µ\", \"ì ì€\", \"ì ìŒ\"]):\n",
    "                return \"ë³´í†µ\"\n",
    "            if any(w in joined for w in [\"ë§ì€\", \"ë§ìŒ\"]):\n",
    "                return \"ë§ì€\"\n",
    "    return None\n",
    "\n",
    "# JSON íŒŒì¼ì—ì„œ íŒ€í”Œ ì¡°ê±´ê³¼ ì¼ì¹˜í•˜ëŠ” ê°•ì˜ í•„í„°ë§\n",
    "def filter_lectures_by_team(json_files, team_condition):\n",
    "    if team_condition in TEAM_CACHE:\n",
    "        return TEAM_CACHE[team_condition]\n",
    "\n",
    "    result = []\n",
    "    for file in json_files:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        for item in data:\n",
    "            team_value = item.get(\"lecture_team\", \"\").strip()\n",
    "            lecture_id = item.get(\"lecture_id\")\n",
    "            lecture_name = item.get(\"lecture_name\")\n",
    "\n",
    "            if not lecture_id or not lecture_name:\n",
    "                continue\n",
    "\n",
    "            if team_condition == \"ì—†ìŒ\" and team_value in [\"ì—†ìŒ\", \"0\"]:\n",
    "                result.append({\"lecture_id\": lecture_id, \"lecture_name\": lecture_name})\n",
    "            elif team_condition == \"ë³´í†µ\" and team_value in [\"ë³´í†µ\", \"ì ì€\"]:\n",
    "                result.append({\"lecture_id\": lecture_id, \"lecture_name\": lecture_name})\n",
    "            elif team_condition == \"ë§ì€\" and team_value in [\"ë§ì€\", \"ë§ìŒ\"]:\n",
    "                result.append({\"lecture_id\": lecture_id, \"lecture_name\": lecture_name})\n",
    "\n",
    "    TEAM_CACHE[team_condition] = result\n",
    "    return result\n",
    "\n",
    "# íŒ€í”Œ ì‘ë‹µ ë©”ì‹œì§€ í¬ë§·\n",
    "def format_team_project_response(team_condition: str, lectures: list):\n",
    "    if not lectures:\n",
    "        return f\"íŒ€í”Œì´ {team_condition} ê°•ì˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    condition_map = {\n",
    "        \"ì—†ìŒ\": \"ì—†ëŠ”\",\n",
    "        \"ë³´í†µ\": \"ì ì€\",\n",
    "        \"ë§ì€\": \"ë§ì€\"\n",
    "    }\n",
    "    label = condition_map.get(team_condition, team_condition)\n",
    "    header = f\"íŒ€í”Œì´ {label} ê°•ì˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\"\n",
    "    body = \"\\n\".join(\n",
    "        f\"{i+1}. {lec['lecture_name']} (í•™ì •ë²ˆí˜¸: {lec['lecture_id']})\"\n",
    "        for i, lec in enumerate(lectures)\n",
    "    )\n",
    "    return f\"{header}\\n{body}\"\n",
    "\n",
    "# JSON ë‚´ íŒ€í”Œ ì¡°ê±´ ì²˜ë¦¬ í•¸ë“¤ëŸ¬\n",
    "def handle_team_project_query(user_input, json_path):\n",
    "    condition = normalize_team_condition(user_input)\n",
    "    if not condition:\n",
    "        return None\n",
    "\n",
    "    filtered_lectures = filter_lectures_by_team([json_path], condition)\n",
    "    seen = set()\n",
    "    unique_lectures = []\n",
    "    for lec in filtered_lectures:\n",
    "        if lec[\"lecture_name\"] not in seen:\n",
    "            seen.add(lec[\"lecture_name\"])\n",
    "            unique_lectures.append(lec)\n",
    "\n",
    "    return format_team_project_response(condition, unique_lectures)\n",
    "\n",
    "# í•™ì  ë° êµê³¼êµ¬ë¶„ì— ë”°ë¥¸ ê°•ì˜ í•„í„°ë§\n",
    "def get_lectures_by_credit_and_type(user_input: str):\n",
    "    credit_match = re.search(r'(\\d)\\s*í•™ì ', user_input)\n",
    "    if not credit_match:\n",
    "        return \"ëª‡ í•™ì ì§œë¦¬ ìˆ˜ì—…ì„ ì›í•˜ì‹œëŠ”ì§€ ì•Œë ¤ì£¼ì„¸ìš”. ì˜ˆ: '2í•™ì  êµì–‘ ìˆ˜ì—… ì•Œë ¤ì¤˜'\"\n",
    "    credit = int(credit_match.group(1))\n",
    "\n",
    "    # ìˆ˜ì—… ìœ í˜• í•„í„°ë§\n",
    "    course_types = []\n",
    "    if \"ì „í•„\" in user_input:\n",
    "        course_types = [\"ì „í•„\"]\n",
    "    elif \"ì „ì„ \" in user_input:\n",
    "        course_types = [\"ì „ì„ \"]\n",
    "    elif \"êµí•„\" in user_input:\n",
    "        course_types = [\"êµí•„\"]\n",
    "    elif \"êµì„ \" in user_input:\n",
    "        course_types = [\"êµì„ \"]\n",
    "    elif \"ì „ê³µ\" in user_input:\n",
    "        course_types = [\"ì „í•„\", \"ì „ì„ \"]\n",
    "    elif \"êµì–‘\" in user_input:\n",
    "        course_types = [\"êµí•„\", \"êµì„ \"]\n",
    "    else:\n",
    "        course_types = [\"ì „í•„\", \"ì „ì„ \", \"êµí•„\", \"êµì„ \"]\n",
    "\n",
    "    count_match = re.search(r'(\\d+)\\s*ê°œ', user_input)\n",
    "    limit = int(count_match.group(1)) if count_match else None\n",
    "\n",
    "    with open(\"./data/kw_chatbot_data - ìˆ˜ê°•ì‹ ì²­ìë£Œì§‘.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        course_data = json.load(f)\n",
    "\n",
    "    results = []\n",
    "    seen = set()\n",
    "    for item in course_data:\n",
    "        course_type = item.get(\"lecture_course_type\", \"\").strip()\n",
    "        credit_val = item.get(\"lecture_hours\") or item.get(\"lecture_credit\")\n",
    "        if not credit_val:\n",
    "            continue\n",
    "        try:\n",
    "            credit_val = int(str(credit_val).strip())\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        professor = item.get(\"lecture_professor\", \"\").strip()\n",
    "        lecture_name = item.get(\"lecture_name\", \"\").strip()\n",
    "        key = (lecture_name, professor)\n",
    "\n",
    "        if course_type in course_types and credit_val == credit and key not in seen:\n",
    "            seen.add(key)\n",
    "            results.append(f\"{lecture_name} (í•™ì •ë²ˆí˜¸: {item['lecture_id']}) - {professor or 'êµìˆ˜ëª… ì—†ìŒ'}\")\n",
    "\n",
    "    if not results:\n",
    "        return f\"{credit}í•™ì ì§œë¦¬ {', '.join(course_types)} ê³¼ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    if limit:\n",
    "        random.shuffle(results)\n",
    "        results = results[:limit]\n",
    "\n",
    "    header = f\"{credit}í•™ì ì§œë¦¬ {', '.join(course_types)} ê³¼ëª© ëª©ë¡ì…ë‹ˆë‹¤:\"\n",
    "    lines = [f\"{i+1}. {lec}\" for i, lec in enumerate(results)]\n",
    "    return header + \"\\n\" + \"\\n\".join(lines)\n",
    "\n",
    "# ì„±ì  â†’ í‰ì  ë§¤í•‘\n",
    "GRADE_TO_POINT = {\n",
    "    \"A+\": 4.5, \"A0\": 4.0, \"B+\": 3.5, \"B0\": 3.0,\n",
    "    \"C+\": 2.5, \"C0\": 2.0, \"F\": 0.0\n",
    "}\n",
    "\n",
    "# ìˆ˜ê°•ì´ë ¥ ë¶ˆëŸ¬ì˜¤ê¸° (ID â†’ íŒŒì¼ëª… ë§¤í•‘)\n",
    "def load_student_data(user_id: str):\n",
    "    filename = f\"data/kw_chatbot_data - {'ê¹€ë¸Œí‹°' if user_id == 'kim' else 'í™ë°ì‚¬'}_ìˆ˜ê°•ì´ë ¥.json\"\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# ì¬ìˆ˜ê°• íšŸìˆ˜ ê³„ì‚°\n",
    "def count_retake_courses(user_id: str):\n",
    "    data = load_student_data(user_id)\n",
    "    course_count = defaultdict(int)\n",
    "    for record in data:\n",
    "        if record.get(\"retake_status\") == \"R\":\n",
    "            course_count[record[\"lecture_name\"]] += 1\n",
    "    return course_count\n",
    "\n",
    "# íŠ¹ì • ê³¼ëª©ì˜ ì„±ì  ì¡°íšŒ\n",
    "def get_course_grade(user_id: str, course_name: str):\n",
    "    data = load_student_data(user_id)\n",
    "    for record in data:\n",
    "        if record[\"lecture_name\"].replace(\" \", \"\") == course_name.replace(\" \", \"\"):\n",
    "            return record[\"lecutre_grade\"]\n",
    "    return None\n",
    "\n",
    "# ì‚¬ìš©ì ì´ë¦„ ë§¤í•‘\n",
    "USER_NAME = {\n",
    "    \"kim\": \"ê¹€ë¸Œí‹°\",\n",
    "    \"hong\": \"í™ë°ì‚¬\"\n",
    "}\n",
    "\n",
    "# í‰ê·  í‰ì  ê³„ì‚° í•¨ìˆ˜\n",
    "# GPA ê³„ì‚° í•¨ìˆ˜ (ì¬ìˆ˜ê°• ë°˜ì˜ ì—¬ë¶€ ë° ì „ê³µ í•„í„° í¬í•¨)\n",
    "def get_gpa_with_retake(user_id: str, exclude_pre_retake: bool = False, course_type: str = None):\n",
    "    data = load_student_data(user_id)\n",
    "    seen = {}\n",
    "    credits, total = 0, 0\n",
    "    for record in data:\n",
    "        key = record['lecture_id']\n",
    "        grade = record['lecutre_grade']\n",
    "        credit = record['lecture_credit']\n",
    "        ctype = record['lecture_course_type']\n",
    "\n",
    "        if course_type and not ctype.startswith(course_type): continue\n",
    "        if exclude_pre_retake and record.get('retake_or_delete_status') == 'Y': continue\n",
    "\n",
    "        if record.get('retake_status') == 'R':\n",
    "            seen[key] = (GRADE_TO_POINT[grade], credit)\n",
    "        elif key not in seen:\n",
    "            seen[key] = (GRADE_TO_POINT[grade], credit)\n",
    "\n",
    "    for point, credit in seen.values():\n",
    "        credits += credit\n",
    "        total += point * credit\n",
    "\n",
    "    if credits == 0:\n",
    "        return \"ê³„ì‚°í•  ìˆ˜ ìˆëŠ” í•™ì ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    name = USER_NAME.get(user_id, user_id)\n",
    "    return f\"{name}ë‹˜ì˜ í‰ê·  í‰ì ì€ {round(total / credits, 2)}ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "# ì¬ìˆ˜ê°•í•œ ê³¼ëª© ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
    "def get_retake_course_names(user_id: str):\n",
    "    data = load_student_data(user_id)\n",
    "    names = [r['lecture_name'] for r in data if r.get('retake_or_delete_status') == 'Y']\n",
    "    return names\n",
    "\n",
    "# ì¬ìˆ˜ê°•í•œ ê³¼ëª© ê°œìˆ˜ ë°˜í™˜\n",
    "def get_retake_course_count(user_id: str):\n",
    "    return len(get_retake_course_names(user_id))\n",
    "\n",
    "# íŠ¹ì • ì„±ì ì„ ë°›ì€ ê³¼ëª© ì¡°íšŒ í•¨ìˆ˜\n",
    "def get_subjects_by_grade(user_id: str, target_grade: str):\n",
    "    data = load_student_data(user_id)\n",
    "    return [r['lecture_name'] for r in data if r['lecutre_grade'] == target_grade]\n",
    "\n",
    "# íŠ¹ì • ê³¼ëª©ì˜ ìµœì¢… ì„±ì  ë°˜í™˜ í•¨ìˆ˜\n",
    "def get_final_grade_for_subject(user_id: str, subject_name: str):\n",
    "    data = load_student_data(user_id)\n",
    "    matches = [r for r in data if r['lecture_name'] == subject_name]\n",
    "    if not matches:\n",
    "        return None\n",
    "    return matches[-1]['lecutre_grade']\n",
    "\n",
    "# ì¬ìˆ˜ê°• íšŸìˆ˜ ê³¼ëª©ë³„ë¡œ ë°˜í™˜\n",
    "def get_retake_course_counts(user_id: str):\n",
    "    data = load_student_data(user_id)\n",
    "    names = [r['lecture_name'] for r in data if r.get('retake_status') == 'R']\n",
    "    return Counter(names)\n",
    "\n",
    "# ì¬ìˆ˜ê°• ê°€ëŠ¥ ê³¼ëª© ì¡°íšŒ í•¨ìˆ˜ (ì •í™•í•˜ê²Œ ì¬ìˆ˜ê°• ì œì™¸ ê¸°ì¤€ ë°˜ì˜)\n",
    "def get_possible_retake_gpa(user_id: str, focus: str = \"all\", list_only: bool = False, fixed_grade: str = None):\n",
    "    data = load_student_data(user_id)\n",
    "    seen = {}\n",
    "    excluded = {}\n",
    "\n",
    "    # ì¬ìˆ˜ê°• í›„ B0 ì´ìƒ ë°›ì€ ê³¼ëª© ì œì™¸\n",
    "    for record in data:\n",
    "        key = record['lecture_id']\n",
    "        grade = record['lecutre_grade']\n",
    "        if record.get('retake_status') == 'R' and GRADE_TO_POINT.get(grade, 0) >= 3.0:\n",
    "            excluded[key] = True\n",
    "\n",
    "    for record in data:\n",
    "        key = record['lecture_id']\n",
    "        grade = record['lecutre_grade']\n",
    "        ctype = record['lecture_course_type']\n",
    "\n",
    "        if record.get('retake_or_delete_status') == 'Y': continue\n",
    "        if key in excluded: continue\n",
    "        if focus == \"major\" and not ctype.startswith(\"ì „ê³µ\"): continue\n",
    "        if GRADE_TO_POINT.get(grade, 5) > 2.5: continue\n",
    "        if key not in seen:\n",
    "            seen[key] = (GRADE_TO_POINT[grade], record['lecture_credit'], record['lecture_name'])\n",
    "\n",
    "    if list_only:\n",
    "        if not seen:\n",
    "            return f\"ì§€ê¸ˆ ì¬ìˆ˜ê°• ê°€ëŠ¥í•œ {'ì „ê³µ ' if focus == 'major' else ''}ê³¼ëª©ì€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        return f\"ì¬ìˆ˜ê°• ê°€ëŠ¥í•œ {'ì „ê³µ ' if focus == 'major' else ''}ê³¼ëª©: \" + \", \".join([v[2] for v in seen.values()])\n",
    "\n",
    "    # GPA simulation part\n",
    "    original_data = load_student_data(user_id)\n",
    "    base = {}\n",
    "    for r in original_data:\n",
    "        key = r['lecture_id']\n",
    "        if r.get('retake_or_delete_status') == 'Y': continue\n",
    "        base[key] = (GRADE_TO_POINT.get(r['lecutre_grade'], 0.0), r['lecture_credit'])\n",
    "\n",
    "    replace_targets = list(seen.items())\n",
    "    grade_options = [fixed_grade] if fixed_grade else list(GRADE_TO_POINT.keys())\n",
    "    responses = []\n",
    "\n",
    "    for combo in itertools.product(grade_options, repeat=len(replace_targets)):\n",
    "        modified = base.copy()\n",
    "        label = []\n",
    "        for (key, (_, credit, name)), g in zip(replace_targets, combo):\n",
    "            modified[key] = (GRADE_TO_POINT[g], credit)\n",
    "            label.append(f\"{name}: {g}\")\n",
    "        total_credits = sum(c for _, c in modified.values())\n",
    "        total_points = sum(p * c for p, c in modified.values())\n",
    "        avg = round(total_points / total_credits, 2)\n",
    "        responses.append(f\"{' / '.join(label)} â†’ ì˜ˆìƒ í‰ì : {avg}\")\n",
    "\n",
    "    return \"\\n\".join(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94033b02-0f38-4165-854b-34bff5846bae",
   "metadata": {},
   "source": [
    "#### ChromaDB ê²€ìƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1f284f1-b25c-4cd5-9321-e4c695293cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import random\n",
    "import itertools\n",
    "from collections import defaultdict, Counter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from functools import lru_cache\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "\n",
    "# LangChain ì»¬ë ‰ì…˜ ì´ë¦„ ê²°ì • í•¨ìˆ˜\n",
    "def get_collection_name(user_input: str, user_id: str) -> str:\n",
    "    q = user_input.lower()\n",
    "    if \"ì§„ë¡œ\" in q or \"ìƒë‹´\" in q:\n",
    "        return \"career_counsel\"\n",
    "    elif \"ì´ìˆ˜\" in q or \"í•™ì \" in q or \"í˜„í™©\" in q or \"í‰ê· \" in q:\n",
    "        return \"academic_status\"\n",
    "    return f\"lecture_search_{user_id}\"\n",
    "\n",
    "# ì¬ìˆ˜ê°• ê°€ëŠ¥ ê³¼ëª© í•„í„°ë§ í•¨ìˆ˜ (ì „ê³µ/êµì–‘ êµ¬ë¶„ í¬í•¨)\n",
    "def get_filtered_retake_courses(user_id: str, focus: str = \"all\") -> list:\n",
    "    data = load_student_data(user_id)\n",
    "    seen = {}\n",
    "    excluded = set()\n",
    "\n",
    "    # ì¬ìˆ˜ê°•í–ˆê³  ì„±ì ì´ B0 ì´ìƒì´ë©´ ì œì™¸\n",
    "    for record in data:\n",
    "        key = record['lecture_id']\n",
    "        grade = record['lecutre_grade']\n",
    "        if record.get('retake_status') == 'R' and GRADE_TO_POINT.get(grade, 0) >= 3.0:\n",
    "            excluded.add(key)\n",
    "        if record.get('retake_or_delete_status') == 'Y':\n",
    "            excluded.add(key)\n",
    "\n",
    "     # ì¬ìˆ˜ê°• ì¡°ê±´ì— ë¶€í•©í•˜ëŠ” ê³¼ëª© ìˆ˜ì§‘\n",
    "    for record in data:\n",
    "        key = record['lecture_id']\n",
    "        grade = record['lecutre_grade']\n",
    "        ctype = record['lecture_course_type']\n",
    "        name = record['lecture_name']\n",
    "\n",
    "        if key in excluded:\n",
    "            continue\n",
    "        if GRADE_TO_POINT.get(grade, 5) > 2.5:\n",
    "            continue\n",
    "        if focus == 'major' and not ctype.startswith(\"ì „ê³µ\"):\n",
    "            continue\n",
    "        if focus == 'liberal' and ctype.startswith(\"ì „ê³µ\"):\n",
    "            continue\n",
    "        if key not in seen:\n",
    "            seen[key] = name\n",
    "\n",
    "    return list(seen.values())\n",
    "\n",
    "# íŒ€í”Œ ì¡°ê±´ë³„ ì‘ë‹µ í¬ë§· êµ¬ì„±\n",
    "def format_team_project_response(team_condition: str, lectures: list):\n",
    "    if not lectures:\n",
    "        return f\"íŒ€í”Œì´ {team_condition} ê°•ì˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    condition_map = {\n",
    "    \"ì—†ìŒ\": \"ì—†ëŠ”\",\n",
    "    \"ë³´í†µ\": \"ì ì€\",\n",
    "    \"ë§ì€\": \"ë§ì€\"\n",
    "    }\n",
    "    label = condition_map.get(team_condition, team_condition)\n",
    "    header = f\"íŒ€í”Œì´ {label} ê°•ì˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\"\n",
    "    body = \"\\n\".join(\n",
    "        f\"{i+1}. {lec['lecture_name']} (í•™ì •ë²ˆí˜¸: {lec['lecture_id']})\"\n",
    "        for i, lec in enumerate(lectures)\n",
    "    )\n",
    "    return f\"{header}\\n{body}\"\n",
    "\n",
    "# ì¡°ë³„ê³¼ì œ/íŒ€í”Œ ì¡°ê±´ íŒŒì‹± ë° ì •ê·œí™”\n",
    "def normalize_team_condition(user_input: str) -> str | None:\n",
    "    condition_map = {\n",
    "        \"ì—†ìŒ\": [\"íŒ€í”Œ ì—†ëŠ”\", \"íŒ€í”Œì´ ì—†ëŠ”\", \"ì¡°ë³„ê³¼ì œ ì—†ëŠ”\", \"ì¡°ë³„ê³¼ì œê°€ ì—†ëŠ”\"],\n",
    "        \"ë³´í†µ\": [\"íŒ€í”Œ ë³´í†µ\", \"íŒ€í”Œì´ ë³´í†µ\", \"ì¡°ë³„ê³¼ì œ ë³´í†µ\", \"ì¡°ë³„ê³¼ì œê°€ ë³´í†µ\", \"íŒ€í”Œ ì ì€\", \"ì¡°ë³„ê³¼ì œ ì ì€\"],\n",
    "        \"ë§ì€\": [\"íŒ€í”Œ ë§ì€\", \"íŒ€í”Œì´ ë§ì€\", \"ì¡°ë³„ê³¼ì œ ë§ì€\", \"ì¡°ë³„ê³¼ì œê°€ ë§ì€\", \"íŒ€í”Œ ë§ìŒ\", \"ì¡°ë³„ê³¼ì œ ë§ìŒ\"]\n",
    "    }\n",
    "    for condition, variants in condition_map.items():\n",
    "        if any(v in user_input for v in variants):\n",
    "            return condition\n",
    "    return None\n",
    "    \n",
    "# ìì—°ì–´ ì§ˆì˜ ì‘ë‹µ ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def answer_query(user_input: str, user_id: str = \"kim\"):\n",
    "    normalized = user_input.lower().replace(\" \", \"\")\n",
    "\n",
    "    # íŠ¹ì • í•™ì  + ê³¼ëª© íƒ€ì… í•„í„°\n",
    "    if re.search(r'\\d\\s*í•™ì ', user_input):\n",
    "        return get_lectures_by_credit_and_type(user_input)\n",
    "\n",
    "    # íŒ€í”Œ ì¡°ê±´ ë¶„ì„ ë° ì‘ë‹µ\n",
    "    team_condition = normalize_team_condition(user_input)\n",
    "    match = re.search(r'(\\d+)\\s*ê°œ', user_input)\n",
    "    count = int(match.group(1)) if match else None\n",
    "\n",
    "    if team_condition:\n",
    "        filtered_lectures = filter_lectures_by_team([\"./data/kw_chatbot_data - ê°•ì˜ í‰ì .json\"], team_condition)\n",
    "        seen = set()\n",
    "        unique_lectures = []\n",
    "        for lec in filtered_lectures:\n",
    "            if lec[\"lecture_name\"] not in seen:\n",
    "                seen.add(lec[\"lecture_name\"])\n",
    "                unique_lectures.append(lec)\n",
    "        if count:\n",
    "            unique_lectures = unique_lectures[:count]\n",
    "        return format_team_project_response(team_condition, unique_lectures)\n",
    "\n",
    "    # ì„±ì  ì´í•˜ í•„í„°\n",
    "    if \"ì´í•˜\" in normalized:\n",
    "        for grade in GRADE_TO_POINT:\n",
    "            if grade.lower() in normalized:\n",
    "                threshold = GRADE_TO_POINT[grade]\n",
    "                target_grades = [g for g, p in GRADE_TO_POINT.items() if p <= threshold]\n",
    "                subjects = [r['lecture_name'] for r in load_student_data(user_id) if r['lecutre_grade'] in target_grades]\n",
    "                return f\"{', '.join(subjects)} ê³¼ëª©ì´ {grade} ì´í•˜ì…ë‹ˆë‹¤.\" if subjects else f\"{grade} ì´í•˜ì¸ ê³¼ëª©ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # ì¬ìˆ˜ê°• íšŸìˆ˜ ì¡°íšŒ\n",
    "    if \"ì¬ìˆ˜ê°•ëª‡ë²ˆí–ˆì–´\" in normalized or \"ë‚˜ëª‡ë²ˆì¬ìˆ˜ê°•í–ˆì–´\" in normalized:\n",
    "        retake_counts = count_retake_courses(user_id)\n",
    "        if not retake_counts:\n",
    "            return \"ì¬ìˆ˜ê°•í•œ ê³¼ëª©ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        parts = [f\"{name} ê³¼ëª©ì„ {count}ë²ˆ\" for name, count in retake_counts.items()]\n",
    "        return f\"{', '.join(parts)} ì¬ìˆ˜ê°•í•˜ì…¨ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # ë‹¨ì¼ ê³¼ëª© ì„±ì  ì¡°íšŒ\n",
    "    if \"ì„±ì ì´ì–´ë•Œ\" in normalized or \"í•™ì ì´ì–´ë•Œ\" in normalized:\n",
    "        course_name = user_input.split()[0].replace(\" \", \"\")\n",
    "        grade = get_course_grade(user_id, course_name)\n",
    "        return f\"{course_name}ì˜ ì„±ì ì€ {grade}ì…ë‹ˆë‹¤.\" if grade else f\"{course_name}ì— ëŒ€í•œ ì„±ì  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # íŠ¹ì • ì„±ì  ë°›ì€ ê³¼ëª© ë‚˜ì—´\n",
    "    for grade in GRADE_TO_POINT:\n",
    "        if grade.lower() in normalized and (\"ë°›ì€ê³¼ëª©\" in normalized or \"ë°›ì€ìˆ˜ì—…\" in normalized):\n",
    "            subjects = [r['lecture_name'] for r in load_student_data(user_id) if r['lecutre_grade'] == grade]\n",
    "            return f\"{', '.join(subjects)} ê³¼ëª©ì—ì„œ {grade}ë¥¼ ë°›ìœ¼ì…¨ìŠµë‹ˆë‹¤.\" if subjects else f\"{grade}ë¥¼ ë°›ì€ ê³¼ëª©ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # ì¬ìˆ˜ê°• ëª©ë¡ ì¡°íšŒ\n",
    "    if \"ì¬ìˆ˜ê°•í•œê±°ë­ìˆì–´\" in normalized or \"ì¬ìˆ˜ê°•í•œê³¼ëª©\" in normalized:\n",
    "        data = load_student_data(user_id)\n",
    "        names = [r['lecture_name'] for r in data if r.get('retake_status') == 'R']\n",
    "        return \", \".join(f\"{name}ì„ ì¬ìˆ˜ê°•í–ˆìŠµë‹ˆë‹¤.\" for name in names) if names else \"ì¬ìˆ˜ê°•í•œ ê³¼ëª©ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # ì „ì²´ í‰ì  ìš”ì²­\n",
    "    if any(k in normalized for k in [\"ì „ì²´ì„±ì í‰ê· \", \"ì „ì²´í•™ì í‰ê· \"]):\n",
    "        return get_gpa_with_retake(user_id)\n",
    "\n",
    "    # ì¬ìˆ˜ê°• ë°˜ì˜í•œ í‰ì  ìš”ì²­\n",
    "    if any(k in normalized for k in [\"ì¬ìˆ˜ê°•í•˜ê³ ì „ì²´í•™ì \", \"ì¬ìˆ˜ê°•ë°˜ì˜ëœí•™ì \", \"ì¬ìˆ˜ê°•ì ìš©í•™ì \", \"ì¬ìˆ˜ê°•í•˜ê³ í•™ì \"]):\n",
    "        return get_gpa_with_retake(user_id, exclude_pre_retake=True)\n",
    "\n",
    "    # ì „ê³µ í‰ê·  ìš”ì²­\n",
    "    if \"ì „ê³µí‰ê· \" in normalized:\n",
    "        return get_gpa_with_retake(user_id, course_type=\"ì „ê³µ\")\n",
    "\n",
    "    # ì¬ìˆ˜ê°• ê°€ëŠ¥í•œ ì „ê³µ ê³¼ëª© ìš”ì²­\n",
    "    if \"ì¬ìˆ˜ê°•ê°€ëŠ¥í•œì „ê³µê³¼ëª©\" in normalized and any(k in normalized for k in [\"ë­ê°€ìˆì–´\", \"ë­ìˆì–´\", \"ë­ì•¼\"]):\n",
    "        filtered = get_filtered_retake_courses(user_id, focus=\"major\")\n",
    "        return f\"ì§€ê¸ˆ ì¬ìˆ˜ê°• ê°€ëŠ¥í•œ ì „ê³µ ê³¼ëª©ì€ {', '.join(filtered)}ì…ë‹ˆë‹¤.\" if filtered else \"ì§€ê¸ˆ ì¬ìˆ˜ê°• ê°€ëŠ¥í•œ ì „ê³µ ê³¼ëª©ì€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # ì „ì²´ ì¬ìˆ˜ê°• ê°€ëŠ¥í•œ ê³¼ëª©\n",
    "    if \"ì¬ìˆ˜ê°•ê°€ëŠ¥í•œê³¼ëª©\" in normalized and any(k in normalized for k in [\"ë­ê°€ìˆì–´\", \"ë­ìˆì–´\", \"ë­ì•¼\"]):\n",
    "        majors = get_filtered_retake_courses(user_id, focus=\"major\")\n",
    "        liberals = get_filtered_retake_courses(user_id, focus=\"liberal\")\n",
    "        total = majors + liberals\n",
    "        return f\"ì§€ê¸ˆ ì¬ìˆ˜ê°• ê°€ëŠ¥í•œ ê³¼ëª©ì€ {', '.join(total)}ì…ë‹ˆë‹¤.\" if total else \"ì§€ê¸ˆ ì¬ìˆ˜ê°• ê°€ëŠ¥í•œ ê³¼ëª©ì€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # ì„±ì  í–¥ìƒ ê°€ì • ì‹œ GPA ì‹œë®¬ë ˆì´ì…˜\n",
    "    if (\"ì¬ìˆ˜ê°•ê°€ëŠ¥í•œê³¼ëª©\" in normalized or \"ì¬ìˆ˜ê°•ê°€ëŠ¥í•œì „ê³µê³¼ëª©\" in normalized) and \"ì„±ì ì˜¬ë¦¬ë©´\" in normalized:\n",
    "        focus = \"major\" if \"ì „ê³µ\" in normalized else \"all\"\n",
    "        for grade in GRADE_TO_POINT:\n",
    "            if grade.lower() + \"ë¡œ\" in normalized:\n",
    "                result = get_possible_retake_gpa(user_id, focus=focus, fixed_grade=grade)\n",
    "                return result[0] if isinstance(result, tuple) else result\n",
    "        return get_possible_retake_gpa(user_id, focus=focus)\n",
    "\n",
    "    collection_name = get_collection_name(user_input, user_id)\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=\"./chroma_db\",\n",
    "        collection_name=collection_name,\n",
    "        embedding_function=embeddings_model\n",
    "    )\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "        ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ìˆ˜ê°• ì´ë ¥ ë˜ëŠ” í•™ì—…/ì§„ë¡œ ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤.\n",
    "        ì§ˆë¬¸ì— ë‹µí•  ë•Œ ë°˜ë“œì‹œ ì •í™•í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•˜ì„¸ìš”.\n",
    "        ì¡°ë³„ê³¼ì œ, íŒ€í”Œ ë§ìŒ ì •ë„, ì‹œí—˜ ì„±ì  ë„ˆê·¸ëŸ¬ì›€ ì •ë„ì— ê´€í•œ ì§ˆë¬¸ì€ ê°•ì˜ í‰ì .jsonë§Œ í™œìš©í•˜ì—¬ ëŒ€ë‹µí•˜ì„¸ìš”.\n",
    "        ë°ì´í„°ì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ë¡œ ì¶”ì¸¡í•˜ì§€ë§ˆì„¸ìš”.\n",
    "\n",
    "        ì„±ì ì€ A+, A0, B+, B0, C+, C0, F ë“±ì˜ í˜•ì‹ì´ë©°, \n",
    "        â— ì ˆëŒ€ ìœ ì‚¬í•œ ë“±ê¸‰ì„ í¬í•¨í•˜ê±°ë‚˜ ì¶”ë¡ í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "        ì˜ˆ: \"A+\"ë¥¼ ìš”ì²­í–ˆì„ ê²½ìš°, ë°˜ë“œì‹œ ì„±ì ì´ \"A+\"ì¸ ê³¼ëª©ë§Œ í¬í•¨í•˜ì„¸ìš”. \"A0\"ëŠ” í¬í•¨í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.\n",
    "\n",
    "        ğŸ“Œ ë‹µë³€ í˜•ì‹ ì§€ì¹¨:\n",
    "        - ì§ˆë¬¸ì— í•´ë‹¹í•˜ëŠ” ë‚´ìš©ì´ **ì—¬ëŸ¬ ê°œì¸ ê²½ìš° ë¹ ì§ì—†ì´ ëª¨ë‘ ë‚˜ì—´**í•˜ì„¸ìš”.\n",
    "        - ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ë§ëì„ ë‹¤ë¥´ê²Œ ì“°ì„¸ìš”.\n",
    "          ì˜ˆ:\n",
    "            - \"ë‚´ê°€ A+ ë°›ì€ ê³¼ëª© ì•Œë ¤ì¤˜\" â†’ \"OOO, OOO ê³¼ëª©ì—ì„œ A+ë¥¼ ë°›ìœ¼ì…¨ìŠµë‹ˆë‹¤.\"\n",
    "            - \"ìë£Œêµ¬ì¡° ì„±ì ì´ ë­ì•¼?\" â†’ \"ìë£Œêµ¬ì¡°ì˜ ì„±ì ì€ B+ì…ë‹ˆë‹¤.\"\n",
    "            - \"ê°ì²´ì§€í–¥í”„ë¡œê·¸ë˜ë°ì´ ì „ì„ ì´ì§€?\" â†’ \"ë„¤, ê°ì²´ì§€í–¥í”„ë¡œê·¸ë˜ë°ì€ ì „í•„ì…ë‹ˆë‹¤.\"\n",
    "            - \"ì „ì²´ í‰ê· ì´ ì–´ë–»ê²Œ ë¼?\" â†’ \"ì „ì²´ ì„±ì  í‰ê· ì€ 3.58ì…ë‹ˆë‹¤.\"\n",
    "        - **ì ˆëŒ€ë¡œ \"ë‹µë³€:\"ìœ¼ë¡œ ì‹œì‘í•˜ì§€ ë§ˆì„¸ìš”. ë¬¸ì¥ì€ ë°”ë¡œ ì‹œì‘í•˜ì„¸ìš”.**\n",
    "        - ì •ì¤‘í•˜ê³  ê°„ê²°í•˜ê²Œ, í•µì‹¬ë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µí•˜ì„¸ìš”.\n",
    "        - ì¶•í•˜ ì¸ì‚¬, ì¶”ê°€ ì§ˆë¬¸ ê¶Œìœ  ë“±ì€ í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "\n",
    "        ë¬¸ì„œ:\n",
    "        {context}\n",
    "\n",
    "        ì§ˆë¬¸:\n",
    "        {question}\n",
    "\n",
    "        ìœ„ ì§€ì¹¨ì„ ë”°ë¼ **ë‹µë³€ ì ‘ë‘ì–´ ì—†ì´** ìì—°ìŠ¤ëŸ½ê²Œ ë§ë¬¸ì„ ì—¬ì„¸ìš”.\n",
    "        \"\"\"\n",
    "    )\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(search_kwargs={\"k\": 20}),\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "    return qa.invoke({\"query\": user_input})[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a8b9514-406e-403e-843b-438f10999cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¡¸ì—…í•˜ë ¤ë©´ 61í•™ì  ë‚¨ì•˜ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ìœ ì‚¬ë„: 1.2529\n",
      "í•™ë²ˆ: 2024204708\n",
      "ê°•ì˜ëª…: í”„ë¡œê·¸ë˜ë°ê¸°ì´ˆ\n",
      "í•™ì •ë²ˆí˜¸: I040-1-8610-01\n",
      "ê°œì„¤ í•™ê³¼: ì •ë³´ìœµí•©í•™ë¶€\n",
      "ì´ìˆ˜ êµ¬ë¶„: êµí•„\n",
      "í•™ì : 3í•™ì \n",
      "ì„±ì : C0\n",
      "ì¬ìˆ˜ê°•/ì‚­ì œ ì—¬ë¶€: Y ...\n",
      "ì¡¸ì—…í•˜ë ¤ë©´ 61í•™ì  ë‚¨ì•˜ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ìœ ì‚¬ë„: 1.2806\n",
      "í•™ë²ˆ: 2024204708\n",
      "ê°•ì˜ëª…: í”„ë¡œê·¸ë˜ë°ê¸°ì´ˆ\n",
      "í•™ì •ë²ˆí˜¸: I040-1-8610-01\n",
      "ê°œì„¤ í•™ê³¼: ì •ë³´ìœµí•©í•™ë¶€\n",
      "ì´ìˆ˜ êµ¬ë¶„: êµí•„\n",
      "í•™ì : 3í•™ì \n",
      "ì„±ì : A0\n",
      "ì¬ìˆ˜ê°• ì—¬ë¶€: R ...\n",
      "ì¡¸ì—…í•˜ë ¤ë©´ 61í•™ì  ë‚¨ì•˜ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ìœ ì‚¬ë„: 1.2868\n",
      "í•™ë²ˆ: 2024204708\n",
      "ê°•ì˜ëª…: ëŒ€í•™ìˆ˜í•™ë°ì—°ìŠµ1\n",
      "í•™ì •ë²ˆí˜¸: 0000-1-4625-08\n",
      "ê°œì„¤ í•™ê³¼: ì „ì²´ê³µí†µ\n",
      "ì´ìˆ˜ êµ¬ë¶„: êµì„ \n",
      "í•™ì : 3í•™ì \n",
      "ì„±ì : B+ ...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "query = \"ë‚˜ ì¡¸ì—…í•˜ë ¤ë©´ ëª‡í•™ì  ë‚¨ì•˜ì–´?\"\n",
    "\n",
    "# Chroma DB ì—°ê²°\n",
    "db = Chroma(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_name=\"lecture_search_kim\",\n",
    "    embedding_function=embeddings_model\n",
    ")\n",
    "\n",
    "# ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ (ìƒìœ„ 5ê°œ)\n",
    "similar_docs = db.similarity_search_with_score(query, k=3)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "for doc, score in similar_docs:\n",
    "    print(answer_query(query, user_id=\"kim\"))\n",
    "    print(f\"\\nìœ ì‚¬ë„: {score:.4f}\")\n",
    "    print(doc.page_content[:300], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "162df12a-800d-4630-aa6c-ace2a76f3785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¹€í˜„ê²½ êµìˆ˜ë‹˜ì˜ ìˆ˜ì—…ìœ¼ë¡œëŠ” ëŒ€í•™ìˆ˜í•™ë°ì—°ìŠµ2ì™€ ê²½ì œì™€ê²½ì˜ì´ ìˆìŠµë‹ˆë‹¤. ë‘ ê³¼ëª© ëª¨ë‘ A+ ì„±ì ì„ ë°›ìœ¼ì…¨ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ìœ ì‚¬ë„: 1.2030\n",
      "í•™ë²ˆ: 2024204708\n",
      "ê°•ì˜ëª…: ì‚¬íšŒí•™ì˜ì´í•´\n",
      "í•™ì •ë²ˆí˜¸: 0000-1-3948-01\n",
      "ê°œì„¤ í•™ê³¼: ì „ì²´ê³µí†µ\n",
      "ì´ìˆ˜ êµ¬ë¶„: êµì„ \n",
      "í•™ì : 3í•™ì \n",
      "ì„±ì : A0 ...\n",
      "ê¹€í˜„ê²½ êµìˆ˜ë‹˜ì˜ ìˆ˜ì—…ìœ¼ë¡œëŠ” 'ëŒ€í•™ìˆ˜í•™ë°ì—°ìŠµ2', 'ê²½ì œì™€ê²½ì˜', 'ìƒí™œì†ì˜ìƒëª…ê³¼í•™', 'ì¸í„°ë„·í™œìš©'ì—ì„œ A+ë¥¼ ë°›ìœ¼ì…¨ìŠµë‹ˆë‹¤. ì´ ê³¼ëª©ë“¤ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ìœ ì‚¬ë„: 1.2091\n",
      "í•™ë²ˆ: 2024204708\n",
      "ê°•ì˜ëª…: ëŒ€í•™ìˆ˜í•™ë°ì—°ìŠµ2\n",
      "í•™ì •ë²ˆí˜¸: 0000-1-4626-11\n",
      "ê°œì„¤ í•™ê³¼: ì „ì²´ê³µí†µ\n",
      "ì´ìˆ˜ êµ¬ë¶„: êµì„ \n",
      "í•™ì : 3í•™ì \n",
      "ì„±ì : A+ ...\n",
      "ê¹€í˜„ê²½ êµìˆ˜ë‹˜ì˜ ìˆ˜ì—…ìœ¼ë¡œëŠ” ëŒ€í•™ìˆ˜í•™ë°ì—°ìŠµ2ì™€ ê²½ì œì™€ê²½ì˜ì´ ìˆìŠµë‹ˆë‹¤. ë‘ ê³¼ëª© ëª¨ë‘ A+ ì„±ì ì„ ë°›ìœ¼ì…¨ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ìœ ì‚¬ë„: 1.2136\n",
      "í•™ë²ˆ: 2024204708\n",
      "ê°•ì˜ëª…: í™˜ê²½ê³¼ìƒíƒœ\n",
      "í•™ì •ë²ˆí˜¸: 0000-2-2994-01\n",
      "ê°œì„¤ í•™ê³¼: ì „ì²´ê³µí†µ\n",
      "ì´ìˆ˜ êµ¬ë¶„: êµì„ \n",
      "í•™ì : 3í•™ì \n",
      "ì„±ì : B+ ...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "query = \"ê¹€í˜„ê²½ êµìˆ˜ë‹˜ ìˆ˜ì—… ì¶”ì²œí•´ì¤˜\"\n",
    "\n",
    "# Chroma DB ì—°ê²°\n",
    "db = Chroma(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_name=\"lecture_search_kim\",\n",
    "    embedding_function=embeddings_model\n",
    ")\n",
    "\n",
    "# ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ (ìƒìœ„ 5ê°œ)\n",
    "similar_docs = db.similarity_search_with_score(query, k=3)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "for doc, score in similar_docs:\n",
    "    print(answer_query(query, user_id=\"kim\"))\n",
    "    print(f\"\\nìœ ì‚¬ë„: {score:.4f}\")\n",
    "    print(doc.page_content[:300], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "827bfd90-0c96-455b-ae4d-acf253d2dbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìš´ë™ êµì–‘ ê³¼ëª©ì— ëŒ€í•œ ì •ë³´ëŠ” ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "\n",
      "ìœ ì‚¬ë„: 1.2402\n",
      "í•™ì •ë²ˆí˜¸: 0000-3-3200-02\n",
      "ê°•ì˜ëª…: ìš´ë™ê³¼ê±´ê°•\n",
      "ê°•ì˜í‰ì : \n",
      "ê³¼ì œ: \n",
      "íŒ€í”Œ: \n",
      "ì„±ì í‰ê°€ì •ë„: \n",
      "ì¶œê²° ë°©ì‹: \n",
      "ì‹œí—˜ íšŸìˆ˜: \n",
      "ì‹œí—˜ ë°©ì‹: \n",
      "ì „ê³µ í•™ì : ì—†ìŒ\n",
      "êµì–‘ í•™ì : ì—†ìŒ\n",
      "ì´ í•™ì : ì—†ìŒ\n",
      "êµìˆ˜ëª…: \n",
      "ìˆ˜ì—… ì‹œê°„: ëª©1,2\n",
      "ê°•ì˜ ìœ í˜•: êµì„ \n",
      "í•™ì : 3ì‹œê°„\n",
      "í•™ê¸°: í•™ê¸°\n",
      "ê°•ì˜ ì„¤ëª…: ì˜ì—­: 6 ...\n",
      "ìš´ë™ êµì–‘ ê³¼ëª©ì— ëŒ€í•œ ì •ë³´ëŠ” ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "\n",
      "ìœ ì‚¬ë„: 1.2444\n",
      "í•™ì •ë²ˆí˜¸: 0000-3-3200-03\n",
      "ê°•ì˜ëª…: ìš´ë™ê³¼ê±´ê°•\n",
      "ê°•ì˜í‰ì : \n",
      "ê³¼ì œ: \n",
      "íŒ€í”Œ: \n",
      "ì„±ì í‰ê°€ì •ë„: \n",
      "ì¶œê²° ë°©ì‹: \n",
      "ì‹œí—˜ íšŸìˆ˜: \n",
      "ì‹œí—˜ ë°©ì‹: \n",
      "ì „ê³µ í•™ì : ì—†ìŒ\n",
      "êµì–‘ í•™ì : ì—†ìŒ\n",
      "ì´ í•™ì : ì—†ìŒ\n",
      "êµìˆ˜ëª…: \n",
      "ìˆ˜ì—… ì‹œê°„: í† 5,6\n",
      "ê°•ì˜ ìœ í˜•: êµì„ \n",
      "í•™ì : 3ì‹œê°„\n",
      "í•™ê¸°: í•™ê¸°\n",
      "ê°•ì˜ ì„¤ëª…: ì˜ì—­: 6 ...\n",
      "ìš´ë™ êµì–‘ ê³¼ëª©ì— ëŒ€í•œ ì •ë³´ëŠ” ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "\n",
      "ìœ ì‚¬ë„: 1.2496\n",
      "í•™ì •ë²ˆí˜¸: 0000-3-3200-01\n",
      "ê°•ì˜ëª…: ìš´ë™ê³¼ê±´ê°•\n",
      "ê°•ì˜í‰ì : \n",
      "ê³¼ì œ: \n",
      "íŒ€í”Œ: \n",
      "ì„±ì í‰ê°€ì •ë„: \n",
      "ì¶œê²° ë°©ì‹: \n",
      "ì‹œí—˜ íšŸìˆ˜: \n",
      "ì‹œí—˜ ë°©ì‹: \n",
      "ì „ê³µ í•™ì : ì—†ìŒ\n",
      "êµì–‘ í•™ì : ì—†ìŒ\n",
      "ì´ í•™ì : ì—†ìŒ\n",
      "êµìˆ˜ëª…: \n",
      "ìˆ˜ì—… ì‹œê°„: ëª©3,4\n",
      "ê°•ì˜ ìœ í˜•: êµì„ \n",
      "í•™ì : 3ì‹œê°„\n",
      "í•™ê¸°: í•™ê¸°\n",
      "ê°•ì˜ ì„¤ëª…: ì˜ì—­: 6 ...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "query = \"ëª©ìš”ì¼ì— ë“£ëŠ” ìš´ë™ êµì–‘ 2ê°œ ì¶”ì²œí•´ì¤˜?\"\n",
    "\n",
    "# Chroma DB ì—°ê²°\n",
    "db = Chroma(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_name=\"lecture_search\",\n",
    "    embedding_function=embeddings_model\n",
    ")\n",
    "\n",
    "# ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ (ìƒìœ„ 5ê°œ)\n",
    "similar_docs = db.similarity_search_with_score(query, k=3)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "for doc, score in similar_docs:\n",
    "    print(answer_query(query))\n",
    "    print(f\"\\nìœ ì‚¬ë„: {score:.4f}\")\n",
    "    print(doc.page_content[:300], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd7d7226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ì˜ì—­ì€ ì „ì²´ê³µí†µì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(answer_query(\"1 ì˜ì—­ì´ ë­ì•¼?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "11f2c992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ì˜ì—­ì€ ì „ì„  ê³¼ëª©ìœ¼ë¡œ, ì •ë³´ìœµí•©í•™ë¶€ì™€ ê´€ë ¨ëœ ê³¼ëª©ë“¤ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(answer_query(\"2ì˜ì—­ì´ ë­ì•¼?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e39de0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 ì˜ì—­ì€ ì „ì„ , êµì„ , ì „í•„ë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(answer_query(\"3 ì˜ì—­ì´ ë­ì•¼?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ad74a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
