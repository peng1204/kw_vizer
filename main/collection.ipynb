{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efa999d7",
   "metadata": {},
   "source": [
    "기능별 collection 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f2641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "import chromadb\n",
    "\n",
    "#API Key 설정 \n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "#임베딩 모델 초기화 \n",
    "embeddings_model = OpenAIEmbeddings(model = 'text-embedding-3-small')\n",
    "\n",
    "#json-> text 파일을 청크로 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "# Chroma 클라이언트\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "#json 파일 정리\n",
    "def load_json_documents(json_files):\n",
    "    docs = []\n",
    "    for file in json_files:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        for item in data: #얘는 파일 별 수정해야해요요\n",
    "            if \"Text\" in item and \"Completion\" in item:\n",
    "                docs.append(Document(\n",
    "                    page_content=f\"질문: {item['Text']}\\n답변: {item['Completion']}\",\n",
    "                    metadata={\"세부전공\": item.get(\"세부전공\", \"\"), \"카테고리\": item.get(\"카테고리\", \"\")}\n",
    "                ))\n",
    "    return docs\n",
    "\n",
    "#결과 확인 (Move this after embeddings are defined)\n",
    "\n",
    "#json -> documents 파일 변환\n",
    "def load_json_documents(json_files):\n",
    "    docs = []\n",
    "    for file in json_files:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        for item in data:\n",
    "            if \"Text\" in item and \"Completion\" in item:\n",
    "                docs.append(Document(\n",
    "                    page_content=f\"질문: {item['Text']}\\n답변: {item['Completion']}\",\n",
    "                    metadata={\"세부전공\": item.get(\"세부전공\", \"\"), \"카테고리\": item.get(\"카테고리\", \"\")}\n",
    "                ))\n",
    "    return docs\n",
    "\n",
    "#각 기능별 json 경로 리스트 \n",
    "task_datasets = {\n",
    "    \"lecture_search\": [\"./data/강의탐색1.json\", \"./data/강의탐색2.json\"],\n",
    "    \"career_counsel\": [\"./data/진로상담1.json\", \"./data/진로상담2.json\"],\n",
    "    \"academic_status\": [\"./data/학업현황1.json\", \"./data/학업현황2.json\"]\n",
    "}\n",
    "\n",
    "# 각 기능별 컬렉션 생성 및 임베딩 처리\n",
    "for task, files in task_datasets.items():\n",
    "    # JSON → Documents\n",
    "    docs = load_json_documents(files)\n",
    "\n",
    "    #청크 분할\n",
    "    split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "    # 청크 텍스트\n",
    "    texts = [doc.page_content for doc in split_docs]\n",
    "\n",
    "    # 임베딩\n",
    "    embeddings = embeddings_model.embed_documents(texts)\n",
    "\n",
    "    # 저장\n",
    "    collection = client.get_or_create_collection(name=task)\n",
    "    collection.add(\n",
    "        documents=texts,\n",
    "        embeddings=embeddings,\n",
    "        ids=[f\"{task}_{i}\" for i in range(len(texts))]\n",
    "    )\n",
    "    \n",
    "    print(\"임베딩 개수:\", len(embeddings))\n",
    "    print(\"벡터 차원:\", len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dd6bde",
   "metadata": {},
   "source": [
    "사용자의 입력을 기능별로 분류\n",
    "강의 탐색 -> 강의탐색기능 \n",
    "학습 현황 -> 학습현황기능\n",
    "진로 상담 -> 진로상담기능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d298b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_function(user_input: str) -> str:\n",
    "    if \"강의\" in user_input or \"탐색\" in user_input:\n",
    "        return \"lecture_search\"\n",
    "    elif \"진로\" in user_input or \"상담\" in user_input:\n",
    "        return \"career_counsel\"\n",
    "    elif \"학업\" in user_input or \"현황\" in user_input:\n",
    "        return \"academic_status\"\n",
    "    else:\n",
    "        return \"lecture_search\"  # fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9a19ec",
   "metadata": {},
   "source": [
    "분류된 기능에 맞춰 ChromaDB 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02049a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.3)\n",
    "\n",
    "def answer_query(user_input: str):\n",
    "    task = classify_function(user_input)\n",
    "\n",
    "    # 컬렉션 로드\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=\"./chroma_db\",\n",
    "        collection_name=task,\n",
    "        embedding_function=embeddings_model\n",
    "    )\n",
    "\n",
    "    # 유사 문서 검색\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type=\"stuff\")\n",
    "\n",
    "    # 답변 생성\n",
    "    return qa.run(user_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
